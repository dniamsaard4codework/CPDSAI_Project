{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a804a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for files in these paths:\n",
      "  ./datasets/2019/201901/CPY015.csv\n",
      "  ./datasets/2019/201902/CPY015.csv\n",
      "  ./datasets/2019/201903/CPY015.csv\n",
      "  ./datasets/2019/201904/CPY015.csv\n",
      "  ./datasets/2019/201905/CPY015.csv\n",
      "  ...\n",
      "Processing: ./datasets/2019/201901/CPY015.csv\n",
      "  Added 4464 rows\n",
      "Processing: ./datasets/2019/201902/CPY015.csv\n",
      "  Added 4032 rows\n",
      "Processing: ./datasets/2019/201903/CPY015.csv\n",
      "  Added 4464 rows\n",
      "Processing: ./datasets/2019/201904/CPY015.csv\n",
      "  Added 4320 rows\n",
      "Processing: ./datasets/2019/201905/CPY015.csv\n",
      "  Added 4464 rows\n",
      "Processing: ./datasets/2019/201906/CPY015.csv\n",
      "  Added 4320 rows\n",
      "Processing: ./datasets/2019/201907/CPY015.csv\n",
      "  Added 4464 rows\n",
      "Processing: ./datasets/2019/201908/CPY015.csv\n",
      "  Added 4464 rows\n",
      "Processing: ./datasets/2019/201909/CPY015.csv\n",
      "  Added 4320 rows\n",
      "Processing: ./datasets/2019/201910/CPY015.csv\n",
      "  Added 4464 rows\n",
      "Processing: ./datasets/2019/201911/CPY015.csv\n",
      "  Added 4320 rows\n",
      "Processing: ./datasets/2019/201912/CPY015.csv\n",
      "  Added 4464 rows\n",
      "Processing: ./datasets/2020/202001/CPY015.csv\n",
      "  Added 4464 rows\n",
      "Processing: ./datasets/2020/202002/CPY015.csv\n",
      "  Added 4176 rows\n",
      "Processing: ./datasets/2020/202003/CPY015.csv\n",
      "  Added 4464 rows\n",
      "Processing: ./datasets/2020/202004/CPY015.csv\n",
      "  Added 4320 rows\n",
      "Processing: ./datasets/2020/202005/CPY015.csv\n",
      "  Added 4464 rows\n",
      "Processing: ./datasets/2020/202006/CPY015.csv\n",
      "  Added 4320 rows\n",
      "Processing: ./datasets/2020/202007/CPY015.csv\n",
      "  Added 4464 rows\n",
      "Processing: ./datasets/2020/202008/CPY015.csv\n",
      "  Added 4464 rows\n",
      "Processing: ./datasets/2020/202009/CPY015.csv\n",
      "  Added 4320 rows\n",
      "Processing: ./datasets/2020/202010/CPY015.csv\n",
      "  Added 4464 rows\n",
      "Processing: ./datasets/2020/202011/CPY015.csv\n",
      "  Added 4320 rows\n",
      "Processing: ./datasets/2020/202012/CPY015.csv\n",
      "  Added 4464 rows\n",
      "Processing: ./datasets/2021/202101/CPY015.csv\n",
      "  Added 4464 rows\n",
      "Processing: ./datasets/2021/202102/CPY015.csv\n",
      "  Added 4032 rows\n",
      "Processing: ./datasets/2021/202103/CPY015.csv\n",
      "  Added 4464 rows\n",
      "Processing: ./datasets/2021/202104/CPY015.csv\n",
      "  Added 4320 rows\n",
      "Processing: ./datasets/2021/202105/CPY015.csv\n",
      "  Added 4464 rows\n",
      "Processing: ./datasets/2021/202106/CPY015.csv\n",
      "  Added 4320 rows\n",
      "Processing: ./datasets/2021/202107/CPY015.csv\n",
      "  Added 4464 rows\n",
      "Processing: ./datasets/2021/202108/CPY015.csv\n",
      "  Added 4464 rows\n",
      "Processing: ./datasets/2021/202109/CPY015.csv\n",
      "  Added 4320 rows\n",
      "Processing: ./datasets/2021/202110/CPY015.csv\n",
      "  Added 4464 rows\n",
      "Processing: ./datasets/2021/202111/CPY015.csv\n",
      "  Added 4320 rows\n",
      "Processing: ./datasets/2021/202112/CPY015.csv\n",
      "  Added 4464 rows\n",
      "Processing: ./datasets/2022/202201/CPY015.csv\n",
      "  Added 4464 rows\n",
      "Processing: ./datasets/2022/202202/CPY015.csv\n",
      "  Added 4032 rows\n",
      "Processing: ./datasets/2022/202203/CPY015.csv\n",
      "  Added 4464 rows\n",
      "Processing: ./datasets/2022/202204/CPY015.csv\n",
      "  Added 4320 rows\n",
      "Processing: ./datasets/2022/202205/CPY015.csv\n",
      "  Added 4464 rows\n",
      "Processing: ./datasets/2022/202206/CPY015.csv\n",
      "  Added 4320 rows\n",
      "Processing: ./datasets/2022/202207/CPY015.csv\n",
      "  Added 4464 rows\n",
      "Processing: ./datasets/2022/202208/CPY015.csv\n",
      "  Added 4464 rows\n",
      "Processing: ./datasets/2022/202209/CPY015.csv\n",
      "  Added 4320 rows\n",
      "Processing: ./datasets/2022/202210/CPY015.csv\n",
      "  Added 4464 rows\n",
      "Processing: ./datasets/2022/202211/CPY015.csv\n",
      "  Added 4320 rows\n",
      "Processing: ./datasets/2022/202212/CPY015.csv\n",
      "  Added 4464 rows\n",
      "Processing: ./datasets/2023/202301/CPY015.csv\n",
      "  Added 4464 rows\n",
      "Processing: ./datasets/2023/202302/CPY015.csv\n",
      "  Added 4032 rows\n",
      "Processing: ./datasets/2023/202303/CPY015.csv\n",
      "  Added 4464 rows\n",
      "Processing: ./datasets/2023/202304/CPY015.csv\n",
      "  Added 4320 rows\n",
      "Processing: ./datasets/2023/202305/CPY015.csv\n",
      "  Added 4464 rows\n",
      "Processing: ./datasets/2023/202306/CPY015.csv\n",
      "  Added 4320 rows\n",
      "Processing: ./datasets/2023/202307/CPY015.csv\n",
      "  Added 4464 rows\n",
      "Processing: ./datasets/2023/202308/CPY015.csv\n",
      "  Added 4464 rows\n",
      "Processing: ./datasets/2023/202309/CPY015.csv\n",
      "  Added 4320 rows\n",
      "Processing: ./datasets/2023/202310/CPY015.csv\n",
      "  Added 4464 rows\n",
      "Processing: ./datasets/2023/202311/CPY015.csv\n",
      "  Added 4320 rows\n",
      "Processing: ./datasets/2023/202312/CPY015.csv\n",
      "  Added 4464 rows\n",
      "Processing: ./datasets/2024/202401/CPY015.csv\n",
      "  Added 4464 rows\n",
      "Processing: ./datasets/2024/202402/CPY015.csv\n",
      "  Added 4176 rows\n",
      "Processing: ./datasets/2024/202403/CPY015.csv\n",
      "  Added 4464 rows\n",
      "Processing: ./datasets/2024/202404/CPY015.csv\n",
      "  Added 4320 rows\n",
      "Processing: ./datasets/2024/202405/CPY015.csv\n",
      "  Added 4464 rows\n",
      "Processing: ./datasets/2024/202406/CPY015.csv\n",
      "  Added 4320 rows\n",
      "Processing: ./datasets/2024/202407/CPY015.csv\n",
      "  Added 4464 rows\n",
      "Processing: ./datasets/2024/202408/CPY015.csv\n",
      "  Added 4464 rows\n",
      "Processing: ./datasets/2024/202409/CPY015.csv\n",
      "  Added 4320 rows\n",
      "Processing: ./datasets/2024/202410/CPY015.csv\n",
      "  Added 4464 rows\n",
      "Processing: ./datasets/2024/202411/CPY015.csv\n",
      "  Added 4320 rows\n",
      "Processing: ./datasets/2024/202412/CPY015.csv\n",
      "  Added 4464 rows\n",
      "Processing: ./datasets/2025/202501/CPY015.csv\n",
      "  Added 4464 rows\n",
      "Processing: ./datasets/2025/202502/CPY015.csv\n",
      "  Added 4032 rows\n",
      "Processing: ./datasets/2025/202503/CPY015.csv\n",
      "  Added 4464 rows\n",
      "Processing: ./datasets/2025/202504/CPY015.csv\n",
      "  Added 4320 rows\n",
      "Processing: ./datasets/2025/202505/CPY015.csv\n",
      "  Added 4464 rows\n",
      "File not found: ./datasets/2025/202506/CPY015.csv\n",
      "File not found: ./datasets/2025/202507/CPY015.csv\n",
      "File not found: ./datasets/2025/202508/CPY015.csv\n",
      "File not found: ./datasets/2025/202509/CPY015.csv\n",
      "File not found: ./datasets/2025/202510/CPY015.csv\n",
      "File not found: ./datasets/2025/202511/CPY015.csv\n",
      "File not found: ./datasets/2025/202512/CPY015.csv\n",
      "\n",
      "Summary:\n",
      "Files found and processed: 77\n",
      "Total data rows in master file: 337392\n",
      "Total columns: 7\n",
      "Output file: master_CPY015.csv\n",
      "Data shape: (337392, 7)\n",
      "\n",
      "First 5 rows:\n",
      "         date      time water_lv station_code measure_datetime  water_level  \\\n",
      "0  2019-01-01  00:00:00     0.59          NaN              NaN          NaN   \n",
      "1  2019-01-01  00:10:00     0.59          NaN              NaN          NaN   \n",
      "2  2019-01-01  00:20:00     0.61          NaN              NaN          NaN   \n",
      "3  2019-01-01  00:30:00     0.63          NaN              NaN          NaN   \n",
      "4  2019-01-01  00:40:00     0.65          NaN              NaN          NaN   \n",
      "\n",
      "  quality_flag  \n",
      "0          NaN  \n",
      "1          NaN  \n",
      "2          NaN  \n",
      "3          NaN  \n",
      "4          NaN  \n",
      "\n",
      "Column names:\n",
      "['date', 'time', 'water_lv', 'station_code', 'measure_datetime', 'water_level', 'quality_flag']\n"
     ]
    }
   ],
   "source": [
    "# Data acquisition \n",
    "\n",
    "# Find all files in each folder that have .csv extension and use pandas concat\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data_main_folders = ['2019','2020','2021', '2022', '2023', '2024', '2025']\n",
    "months = [f'{i:02d}' for i in range(1, 13)]\n",
    "# Sub folder example: 2021/202101, 2021/202102, ..., 2021/202112\n",
    "# Fixed the path construction to match actual folder structure\n",
    "sub_folders = [f'./datasets/{folder}/{folder}{month}' for folder in data_main_folders for month in months]\n",
    "\n",
    "print(\"Looking for files in these paths:\")\n",
    "for folder in sub_folders[:5]:  # Show first 5 paths as example\n",
    "    print(f\"  {folder}/CPY015.csv\")\n",
    "print(\"  ...\")\n",
    "\n",
    "# Read and concat all csv files with name \"CPY015.csv\" in each sub folder using pandas\n",
    "master_out = 'master_CPY015.csv'\n",
    "files_found = 0\n",
    "dataframes = []\n",
    "\n",
    "for sub_folder in sub_folders:\n",
    "    file_path = f'{sub_folder}/CPY015.csv'\n",
    "    if os.path.exists(file_path):\n",
    "        files_found += 1\n",
    "        print(f\"Processing: {file_path}\")\n",
    "        try:\n",
    "            # Read CSV file into DataFrame\n",
    "            df = pd.read_csv(file_path)\n",
    "            dataframes.append(df)\n",
    "            print(f\"  Added {len(df)} rows\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Error reading file: {e}\")\n",
    "    else:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "if dataframes:\n",
    "    master_df = pd.concat(dataframes, ignore_index=True)\n",
    "    \n",
    "    # Save to CSV\n",
    "    master_df.to_csv(master_out, index=False)\n",
    "    \n",
    "    print(f\"\\nSummary:\")\n",
    "    print(f\"Files found and processed: {files_found}\")\n",
    "    print(f\"Total data rows in master file: {len(master_df)}\")\n",
    "    print(f\"Total columns: {len(master_df.columns)}\")\n",
    "    print(f\"Output file: {master_out}\")\n",
    "    print(f\"Data shape: {master_df.shape}\")\n",
    "    \n",
    "    # Display first few rows and basic info\n",
    "    print(f\"\\nFirst 5 rows:\")\n",
    "    print(master_df.head())\n",
    "    print(f\"\\nColumn names:\")\n",
    "    print(master_df.columns.tolist())\n",
    "else:\n",
    "    print(\"No data files found to concatenate!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b13187f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checked files in: ./datasets/2019/201901\n",
      "Checked files in: ./datasets/2019/201902\n",
      "Checked files in: ./datasets/2019/201903\n",
      "Checked files in: ./datasets/2019/201904\n",
      "Checked files in: ./datasets/2019/201905\n",
      "Checked files in: ./datasets/2019/201906\n",
      "Checked files in: ./datasets/2019/201907\n",
      "Checked files in: ./datasets/2019/201908\n",
      "Checked files in: ./datasets/2019/201909\n",
      "Checked files in: ./datasets/2019/201910\n",
      "Checked files in: ./datasets/2019/201911\n",
      "Checked files in: ./datasets/2019/201912\n",
      "Checked files in: ./datasets/2020/202001\n",
      "Checked files in: ./datasets/2020/202002\n",
      "Checked files in: ./datasets/2020/202003\n",
      "Checked files in: ./datasets/2020/202004\n",
      "Checked files in: ./datasets/2020/202005\n",
      "Checked files in: ./datasets/2020/202006\n",
      "Checked files in: ./datasets/2020/202007\n",
      "Checked files in: ./datasets/2020/202008\n",
      "Checked files in: ./datasets/2020/202009\n",
      "Checked files in: ./datasets/2020/202010\n",
      "Checked files in: ./datasets/2020/202011\n",
      "Checked files in: ./datasets/2020/202012\n",
      "Checked files in: ./datasets/2021/202101\n",
      "Checked files in: ./datasets/2021/202102\n",
      "Checked files in: ./datasets/2021/202103\n",
      "Checked files in: ./datasets/2021/202104\n",
      "Checked files in: ./datasets/2021/202105\n",
      "Checked files in: ./datasets/2021/202106\n",
      "Checked files in: ./datasets/2021/202107\n",
      "Checked files in: ./datasets/2021/202108\n",
      "Checked files in: ./datasets/2021/202109\n",
      "Checked files in: ./datasets/2021/202110\n",
      "Checked files in: ./datasets/2021/202111\n",
      "Checked files in: ./datasets/2021/202112\n",
      "Checked files in: ./datasets/2022/202201\n",
      "Checked files in: ./datasets/2022/202202\n",
      "Checked files in: ./datasets/2022/202203\n",
      "Checked files in: ./datasets/2022/202204\n",
      "Checked files in: ./datasets/2022/202205\n",
      "Checked files in: ./datasets/2022/202206\n",
      "Checked files in: ./datasets/2022/202207\n",
      "Checked files in: ./datasets/2022/202208\n",
      "Checked files in: ./datasets/2022/202209\n",
      "Checked files in: ./datasets/2022/202210\n",
      "Checked files in: ./datasets/2022/202211\n",
      "Checked files in: ./datasets/2022/202212\n",
      "Checked files in: ./datasets/2023/202301\n",
      "Checked files in: ./datasets/2023/202302\n",
      "Checked files in: ./datasets/2023/202303\n",
      "Checked files in: ./datasets/2023/202304\n",
      "Checked files in: ./datasets/2023/202305\n",
      "Checked files in: ./datasets/2023/202306\n",
      "Checked files in: ./datasets/2023/202307\n",
      "Checked files in: ./datasets/2023/202308\n",
      "Checked files in: ./datasets/2023/202309\n",
      "Checked files in: ./datasets/2023/202310\n",
      "Checked files in: ./datasets/2023/202311\n",
      "Checked files in: ./datasets/2023/202312\n",
      "Checked files in: ./datasets/2024/202401\n",
      "Checked files in: ./datasets/2024/202402\n",
      "Checked files in: ./datasets/2024/202403\n",
      "Checked files in: ./datasets/2024/202404\n",
      "Checked files in: ./datasets/2024/202405\n",
      "Checked files in: ./datasets/2024/202406\n",
      "Checked files in: ./datasets/2024/202407\n",
      "Checked files in: ./datasets/2024/202408\n",
      "Checked files in: ./datasets/2024/202409\n",
      "Checked files in: ./datasets/2024/202410\n",
      "Checked files in: ./datasets/2024/202411\n",
      "Checked files in: ./datasets/2024/202412\n",
      "Checked files in: ./datasets/2025/202501\n",
      "Checked files in: ./datasets/2025/202502\n",
      "Checked files in: ./datasets/2025/202503\n",
      "Checked files in: ./datasets/2025/202504\n",
      "Checked files in: ./datasets/2025/202505\n",
      "Folder does not exist: ./datasets/2025/202506\n",
      "Folder does not exist: ./datasets/2025/202507\n",
      "Folder does not exist: ./datasets/2025/202508\n",
      "Folder does not exist: ./datasets/2025/202509\n",
      "Folder does not exist: ./datasets/2025/202510\n",
      "Folder does not exist: ./datasets/2025/202511\n",
      "Folder does not exist: ./datasets/2025/202512\n",
      "Cleanup complete.\n"
     ]
    }
   ],
   "source": [
    "# Remove other files that are not related to above process\n",
    "\n",
    "# Check if folder exists and only contains CPY015.csv, remove other files\n",
    "for sub_folder in sub_folders:\n",
    "    # Check if the folder exists first\n",
    "    if os.path.exists(sub_folder):\n",
    "        try:\n",
    "            files_in_folder = os.listdir(sub_folder)\n",
    "            for file in files_in_folder:\n",
    "                if file != 'CPY015.csv':\n",
    "                    file_path = os.path.join(sub_folder, file)\n",
    "                    try:\n",
    "                        os.remove(file_path)\n",
    "                        print(f\"Removed unrelated file: {file_path}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error removing file {file_path}: {e}\")\n",
    "            print(f\"Checked files in: {sub_folder}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error accessing folder {sub_folder}: {e}\")\n",
    "    else:\n",
    "        print(f\"Folder does not exist: {sub_folder}\")\n",
    "\n",
    "print(\"Cleanup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dee599b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 337392 entries, 0 to 337391\n",
      "Data columns (total 7 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   date              289152 non-null  object \n",
      " 1   time              289152 non-null  object \n",
      " 2   water_lv          289152 non-null  object \n",
      " 3   station_code      48240 non-null   object \n",
      " 4   measure_datetime  48240 non-null   object \n",
      " 5   water_level       48061 non-null   float64\n",
      " 6   quality_flag      48061 non-null   object \n",
      "dtypes: float64(1), object(6)\n",
      "memory usage: 18.0+ MB\n",
      "\n",
      "Original shape: (337392, 7)\n",
      "\n",
      "Column names: ['date', 'time', 'water_lv', 'station_code', 'measure_datetime', 'water_level', 'quality_flag']\n",
      "\n",
      "First 5 rows:\n",
      "         date      time water_lv station_code measure_datetime  water_level  \\\n",
      "0  2019-01-01  00:00:00     0.59          NaN              NaN          NaN   \n",
      "1  2019-01-01  00:10:00     0.59          NaN              NaN          NaN   \n",
      "2  2019-01-01  00:20:00     0.61          NaN              NaN          NaN   \n",
      "3  2019-01-01  00:30:00     0.63          NaN              NaN          NaN   \n",
      "4  2019-01-01  00:40:00     0.65          NaN              NaN          NaN   \n",
      "\n",
      "  quality_flag  \n",
      "0          NaN  \n",
      "1          NaN  \n",
      "2          NaN  \n",
      "3          NaN  \n",
      "4          NaN  \n",
      "\n",
      "Last 5 rows:\n",
      "       date time water_lv station_code     measure_datetime  water_level  \\\n",
      "337387  NaN  NaN      NaN       CPY015  2025-05-31 23:10:00         1.63   \n",
      "337388  NaN  NaN      NaN       CPY015  2025-05-31 23:20:00         1.62   \n",
      "337389  NaN  NaN      NaN       CPY015  2025-05-31 23:30:00         1.60   \n",
      "337390  NaN  NaN      NaN       CPY015  2025-05-31 23:40:00         1.60   \n",
      "337391  NaN  NaN      NaN       CPY015  2025-05-31 23:50:00         1.60   \n",
      "\n",
      "       quality_flag  \n",
      "337387            N  \n",
      "337388            N  \n",
      "337389            N  \n",
      "337390            N  \n",
      "337391            N  \n",
      "\n",
      "Data format analysis:\n",
      "Rows with old format (date, time, water_lv): 289152\n",
      "Rows with new format (station_code, measure_datetime, water_level): 48061\n",
      "\n",
      "Unique station codes: ['CPY015']\n",
      "Water_lv data type examples: 0    0.59\n",
      "1    0.59\n",
      "2    0.61\n",
      "3    0.63\n",
      "4    0.65\n",
      "Name: water_lv, dtype: object\n",
      "Water_level data type examples: 289152    0.91\n",
      "289153    0.86\n",
      "289154    0.84\n",
      "289155    0.87\n",
      "289156    0.91\n",
      "Name: water_level, dtype: float64\n",
      "\n",
      "Date format examples:\n",
      "date column: ['2019-01-01', '2019-01-01', '2019-01-01']\n",
      "measure_datetime column: ['2024-07-01 00:00:00', '2024-07-01 00:10:00', '2024-07-01 00:20:00']\n"
     ]
    }
   ],
   "source": [
    "# Clean the data of master_CPY015.csv\n",
    "\n",
    "# Read with low_memory=False to avoid dtype warnings\n",
    "df_master = pd.read_csv(\"master_CPY015.csv\", low_memory=False)\n",
    "print(\"Original data info:\")\n",
    "df_master.info()\n",
    "print(f\"\\nOriginal shape: {df_master.shape}\")\n",
    "print(f\"\\nColumn names: {df_master.columns.tolist()}\")\n",
    "\n",
    "# Display sample data to understand the structure\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "print(df_master.head())\n",
    "print(f\"\\nLast 5 rows:\")\n",
    "print(df_master.tail())\n",
    "\n",
    "# Check for different data formats by looking at non-null patterns\n",
    "print(f\"\\nData format analysis:\")\n",
    "print(\"Rows with old format (date, time, water_lv):\", df_master[['date', 'time', 'water_lv']].dropna().shape[0])\n",
    "print(\"Rows with new format (station_code, measure_datetime, water_level):\", df_master[['station_code', 'measure_datetime', 'water_level']].dropna().shape[0])\n",
    "\n",
    "# Check unique values in some columns\n",
    "print(f\"\\nUnique station codes: {df_master['station_code'].dropna().unique()}\")\n",
    "print(f\"Water_lv data type examples: {df_master['water_lv'].dropna().head()}\")\n",
    "print(f\"Water_level data type examples: {df_master['water_level'].dropna().head()}\")\n",
    "\n",
    "# Check date formats\n",
    "print(f\"\\nDate format examples:\")\n",
    "print(\"date column:\", df_master['date'].dropna().head(3).tolist())\n",
    "print(\"measure_datetime column:\", df_master['measure_datetime'].dropna().head(3).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6b6a302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                 48240\n",
       "time                 48240\n",
       "water_lv             48240\n",
       "station_code        289152\n",
       "measure_datetime    289152\n",
       "water_level         289331\n",
       "quality_flag        289331\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_master.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "775ed25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STEP 1: Separate and standardize different data formats ===\n",
      "Old format rows: 289152\n",
      "New format rows: 48061\n",
      "\n",
      "=== STEP 2: Processing old format data ===\n",
      "Old format after processing: 289152 rows\n",
      "Valid datetime records: 289152\n",
      "Valid water level records: 272804\n",
      "\n",
      "=== STEP 3: Processing new format data ===\n",
      "New format after processing: 48061 rows\n",
      "Valid datetime records: 48061\n",
      "Valid water level records: 48061\n",
      "\n",
      "=== STEP 4: Combine and clean final dataset ===\n",
      "Combined data shape: (337213, 5)\n",
      "After removing duplicates: (337213, 5)\n",
      "\n",
      "=== STEP 5: Data quality summary ===\n",
      "Final clean dataset shape: (337213, 9)\n",
      "Date range: 2019-01-01 00:00:00 to 2025-05-31 23:50:00\n",
      "Water level range: -26.39 to 11.54\n",
      "Years covered: [np.int32(2019), np.int32(2020), np.int32(2021), np.int32(2022), np.int32(2023), np.int32(2024), np.int32(2025)]\n",
      "Data by source format:\n",
      "source_format\n",
      "old    289152\n",
      "new     48061\n",
      "Name: count, dtype: int64\n",
      "\n",
      "First 5 rows of cleaned data:\n",
      "  station_code    measure_datetime  water_level quality_flag source_format  \\\n",
      "0       CPY015 2019-01-01 00:00:00         0.59   old_format           old   \n",
      "1       CPY015 2019-01-01 00:10:00         0.59   old_format           old   \n",
      "2       CPY015 2019-01-01 00:20:00         0.61   old_format           old   \n",
      "3       CPY015 2019-01-01 00:30:00         0.63   old_format           old   \n",
      "4       CPY015 2019-01-01 00:40:00         0.65   old_format           old   \n",
      "\n",
      "   year  month  day  hour  \n",
      "0  2019      1    1     0  \n",
      "1  2019      1    1     0  \n",
      "2  2019      1    1     0  \n",
      "3  2019      1    1     0  \n",
      "4  2019      1    1     0  \n",
      "\n",
      "Cleaned data saved to: master_CPY015_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive data cleaning and standardization\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Create a copy for cleaning\n",
    "df_clean = df_master.copy()\n",
    "\n",
    "print(\"=== STEP 1: Separate and standardize different data formats ===\")\n",
    "\n",
    "# Identify old format data (has date, time, water_lv)\n",
    "old_format_mask = df_clean[['date', 'time', 'water_lv']].notnull().all(axis=1)\n",
    "old_format_data = df_clean[old_format_mask].copy()\n",
    "\n",
    "# Identify new format data (has station_code, measure_datetime, water_level)\n",
    "new_format_mask = df_clean[['station_code', 'measure_datetime', 'water_level']].notnull().all(axis=1)\n",
    "new_format_data = df_clean[new_format_mask].copy()\n",
    "\n",
    "print(f\"Old format rows: {len(old_format_data)}\")\n",
    "print(f\"New format rows: {len(new_format_data)}\")\n",
    "\n",
    "# Standardize old format data\n",
    "if len(old_format_data) > 0:\n",
    "    print(\"\\n=== STEP 2: Processing old format data ===\")\n",
    "    \n",
    "    # Combine date and time columns for old format\n",
    "    old_format_data['datetime_combined'] = pd.to_datetime(\n",
    "        old_format_data['date'] + ' ' + old_format_data['time'], \n",
    "        errors='coerce'\n",
    "    )\n",
    "    \n",
    "    # Convert water_lv to numeric (it might be stored as string)\n",
    "    old_format_data['water_level_clean'] = pd.to_numeric(old_format_data['water_lv'], errors='coerce')\n",
    "    \n",
    "    # Add station code (assuming all data is from CPY015)\n",
    "    old_format_data['station_code_clean'] = 'CPY015'\n",
    "    \n",
    "    # Create standardized dataframe for old format\n",
    "    old_standardized = pd.DataFrame({\n",
    "        'station_code': old_format_data['station_code_clean'],\n",
    "        'measure_datetime': old_format_data['datetime_combined'],\n",
    "        'water_level': old_format_data['water_level_clean'],\n",
    "        'quality_flag': 'old_format',  # Mark as old format\n",
    "        'source_format': 'old'\n",
    "    })\n",
    "    \n",
    "    print(f\"Old format after processing: {len(old_standardized)} rows\")\n",
    "    print(f\"Valid datetime records: {old_standardized['measure_datetime'].notnull().sum()}\")\n",
    "    print(f\"Valid water level records: {old_standardized['water_level'].notnull().sum()}\")\n",
    "\n",
    "# Standardize new format data\n",
    "if len(new_format_data) > 0:\n",
    "    print(\"\\n=== STEP 3: Processing new format data ===\")\n",
    "    \n",
    "    # Convert measure_datetime to proper datetime\n",
    "    new_format_data['datetime_clean'] = pd.to_datetime(new_format_data['measure_datetime'], errors='coerce')\n",
    "    \n",
    "    # Create standardized dataframe for new format\n",
    "    new_standardized = pd.DataFrame({\n",
    "        'station_code': new_format_data['station_code'],\n",
    "        'measure_datetime': new_format_data['datetime_clean'],\n",
    "        'water_level': new_format_data['water_level'],\n",
    "        'quality_flag': new_format_data['quality_flag'],\n",
    "        'source_format': 'new'\n",
    "    })\n",
    "    \n",
    "    print(f\"New format after processing: {len(new_standardized)} rows\")\n",
    "    print(f\"Valid datetime records: {new_standardized['measure_datetime'].notnull().sum()}\")\n",
    "    print(f\"Valid water level records: {new_standardized['water_level'].notnull().sum()}\")\n",
    "\n",
    "print(\"\\n=== STEP 4: Combine and clean final dataset ===\")\n",
    "\n",
    "# Combine both formats\n",
    "dataframes_to_combine = []\n",
    "if len(old_format_data) > 0:\n",
    "    dataframes_to_combine.append(old_standardized)\n",
    "if len(new_format_data) > 0:\n",
    "    dataframes_to_combine.append(new_standardized)\n",
    "\n",
    "if dataframes_to_combine:\n",
    "    df_combined = pd.concat(dataframes_to_combine, ignore_index=True)\n",
    "else:\n",
    "    df_combined = pd.DataFrame(columns=['station_code', 'measure_datetime', 'water_level', 'quality_flag', 'source_format'])\n",
    "\n",
    "print(f\"Combined data shape: {df_combined.shape}\")\n",
    "\n",
    "# Remove rows with missing essential data\n",
    "df_final = df_combined.copy()\n",
    "\n",
    "# Remove duplicate records (same datetime and station)\n",
    "df_final = df_final.drop_duplicates(subset=['station_code', 'measure_datetime'], keep='first')\n",
    "print(f\"After removing duplicates: {df_final.shape}\")\n",
    "\n",
    "# Sort by datetime\n",
    "df_final = df_final.sort_values('measure_datetime').reset_index(drop=True)\n",
    "\n",
    "# Add additional time-based columns for analysis\n",
    "df_final['year'] = df_final['measure_datetime'].dt.year\n",
    "df_final['month'] = df_final['measure_datetime'].dt.month\n",
    "df_final['day'] = df_final['measure_datetime'].dt.day\n",
    "df_final['hour'] = df_final['measure_datetime'].dt.hour\n",
    "\n",
    "print(\"\\n=== STEP 5: Data quality summary ===\")\n",
    "print(f\"Final clean dataset shape: {df_final.shape}\")\n",
    "print(f\"Date range: {df_final['measure_datetime'].min()} to {df_final['measure_datetime'].max()}\")\n",
    "print(f\"Water level range: {df_final['water_level'].min():.2f} to {df_final['water_level'].max():.2f}\")\n",
    "print(f\"Years covered: {sorted(df_final['year'].unique())}\")\n",
    "print(f\"Data by source format:\")\n",
    "print(df_final['source_format'].value_counts())\n",
    "\n",
    "print(f\"\\nFirst 5 rows of cleaned data:\")\n",
    "print(df_final.head())\n",
    "\n",
    "# Save cleaned data\n",
    "df_final.to_csv('master_CPY015_cleaned.csv', index=False)\n",
    "print(f\"\\nCleaned data saved to: master_CPY015_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "925a9453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(337213, 9)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_code</th>\n",
       "      <th>measure_datetime</th>\n",
       "      <th>water_level</th>\n",
       "      <th>quality_flag</th>\n",
       "      <th>source_format</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CPY015</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>0.59</td>\n",
       "      <td>old_format</td>\n",
       "      <td>old</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CPY015</td>\n",
       "      <td>2019-01-01 00:10:00</td>\n",
       "      <td>0.59</td>\n",
       "      <td>old_format</td>\n",
       "      <td>old</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CPY015</td>\n",
       "      <td>2019-01-01 00:20:00</td>\n",
       "      <td>0.61</td>\n",
       "      <td>old_format</td>\n",
       "      <td>old</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CPY015</td>\n",
       "      <td>2019-01-01 00:30:00</td>\n",
       "      <td>0.63</td>\n",
       "      <td>old_format</td>\n",
       "      <td>old</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CPY015</td>\n",
       "      <td>2019-01-01 00:40:00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>old_format</td>\n",
       "      <td>old</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  station_code    measure_datetime  water_level quality_flag source_format  \\\n",
       "0       CPY015 2019-01-01 00:00:00         0.59   old_format           old   \n",
       "1       CPY015 2019-01-01 00:10:00         0.59   old_format           old   \n",
       "2       CPY015 2019-01-01 00:20:00         0.61   old_format           old   \n",
       "3       CPY015 2019-01-01 00:30:00         0.63   old_format           old   \n",
       "4       CPY015 2019-01-01 00:40:00         0.65   old_format           old   \n",
       "\n",
       "   year  month  day  hour  \n",
       "0  2019      1    1     0  \n",
       "1  2019      1    1     0  \n",
       "2  2019      1    1     0  \n",
       "3  2019      1    1     0  \n",
       "4  2019      1    1     0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display cleaned data header\n",
    "display(df_final.shape)\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13194031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      "station_code            0\n",
      "measure_datetime        0\n",
      "water_level         16348\n",
      "quality_flag            0\n",
      "source_format           0\n",
      "year                    0\n",
      "month                   0\n",
      "day                     0\n",
      "hour                    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_values = df_final.isnull().sum()\n",
    "print(\"Missing values in each column:\")\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b86e9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_code</th>\n",
       "      <th>measure_datetime</th>\n",
       "      <th>water_level</th>\n",
       "      <th>quality_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>CPY015</td>\n",
       "      <td>2025-05-04 23:40:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>CPY015</td>\n",
       "      <td>2025-05-06 09:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>CPY015</td>\n",
       "      <td>2025-05-06 11:40:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>CPY015</td>\n",
       "      <td>2025-05-06 16:50:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157</th>\n",
       "      <td>CPY015</td>\n",
       "      <td>2025-05-09 00:50:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>CPY015</td>\n",
       "      <td>2025-05-09 21:40:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1711</th>\n",
       "      <td>CPY015</td>\n",
       "      <td>2025-05-12 21:10:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>CPY015</td>\n",
       "      <td>2025-05-14 16:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2852</th>\n",
       "      <td>CPY015</td>\n",
       "      <td>2025-05-20 19:20:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3038</th>\n",
       "      <td>CPY015</td>\n",
       "      <td>2025-05-22 02:20:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3047</th>\n",
       "      <td>CPY015</td>\n",
       "      <td>2025-05-22 03:50:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3058</th>\n",
       "      <td>CPY015</td>\n",
       "      <td>2025-05-22 05:40:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3063</th>\n",
       "      <td>CPY015</td>\n",
       "      <td>2025-05-22 06:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3065</th>\n",
       "      <td>CPY015</td>\n",
       "      <td>2025-05-22 06:50:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3066</th>\n",
       "      <td>CPY015</td>\n",
       "      <td>2025-05-22 07:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3069</th>\n",
       "      <td>CPY015</td>\n",
       "      <td>2025-05-22 07:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3070</th>\n",
       "      <td>CPY015</td>\n",
       "      <td>2025-05-22 07:40:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3072</th>\n",
       "      <td>CPY015</td>\n",
       "      <td>2025-05-22 08:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3075</th>\n",
       "      <td>CPY015</td>\n",
       "      <td>2025-05-22 08:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3077</th>\n",
       "      <td>CPY015</td>\n",
       "      <td>2025-05-22 08:50:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3079</th>\n",
       "      <td>CPY015</td>\n",
       "      <td>2025-05-22 09:10:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3081</th>\n",
       "      <td>CPY015</td>\n",
       "      <td>2025-05-22 09:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3082</th>\n",
       "      <td>CPY015</td>\n",
       "      <td>2025-05-22 09:40:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3084</th>\n",
       "      <td>CPY015</td>\n",
       "      <td>2025-05-22 10:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3085</th>\n",
       "      <td>CPY015</td>\n",
       "      <td>2025-05-22 10:10:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3087</th>\n",
       "      <td>CPY015</td>\n",
       "      <td>2025-05-22 10:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089</th>\n",
       "      <td>CPY015</td>\n",
       "      <td>2025-05-22 10:50:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3092</th>\n",
       "      <td>CPY015</td>\n",
       "      <td>2025-05-22 11:20:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3095</th>\n",
       "      <td>CPY015</td>\n",
       "      <td>2025-05-22 11:50:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3103</th>\n",
       "      <td>CPY015</td>\n",
       "      <td>2025-05-22 13:10:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3104</th>\n",
       "      <td>CPY015</td>\n",
       "      <td>2025-05-22 13:20:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3107</th>\n",
       "      <td>CPY015</td>\n",
       "      <td>2025-05-22 13:50:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3110</th>\n",
       "      <td>CPY015</td>\n",
       "      <td>2025-05-22 14:20:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3113</th>\n",
       "      <td>CPY015</td>\n",
       "      <td>2025-05-22 14:50:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3129</th>\n",
       "      <td>CPY015</td>\n",
       "      <td>2025-05-22 17:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3705</th>\n",
       "      <td>CPY015</td>\n",
       "      <td>2025-05-26 17:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3792</th>\n",
       "      <td>CPY015</td>\n",
       "      <td>2025-05-27 08:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3958</th>\n",
       "      <td>CPY015</td>\n",
       "      <td>2025-05-28 11:40:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4095</th>\n",
       "      <td>CPY015</td>\n",
       "      <td>2025-05-29 10:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     station_code     measure_datetime  water_level quality_flag\n",
       "574        CPY015  2025-05-04 23:40:00          NaN          NaN\n",
       "774        CPY015  2025-05-06 09:00:00          NaN          NaN\n",
       "790        CPY015  2025-05-06 11:40:00          NaN          NaN\n",
       "821        CPY015  2025-05-06 16:50:00          NaN          NaN\n",
       "1157       CPY015  2025-05-09 00:50:00          NaN          NaN\n",
       "1282       CPY015  2025-05-09 21:40:00          NaN          NaN\n",
       "1711       CPY015  2025-05-12 21:10:00          NaN          NaN\n",
       "1971       CPY015  2025-05-14 16:30:00          NaN          NaN\n",
       "2852       CPY015  2025-05-20 19:20:00          NaN          NaN\n",
       "3038       CPY015  2025-05-22 02:20:00          NaN          NaN\n",
       "3047       CPY015  2025-05-22 03:50:00          NaN          NaN\n",
       "3058       CPY015  2025-05-22 05:40:00          NaN          NaN\n",
       "3063       CPY015  2025-05-22 06:30:00          NaN          NaN\n",
       "3065       CPY015  2025-05-22 06:50:00          NaN          NaN\n",
       "3066       CPY015  2025-05-22 07:00:00          NaN          NaN\n",
       "3069       CPY015  2025-05-22 07:30:00          NaN          NaN\n",
       "3070       CPY015  2025-05-22 07:40:00          NaN          NaN\n",
       "3072       CPY015  2025-05-22 08:00:00          NaN          NaN\n",
       "3075       CPY015  2025-05-22 08:30:00          NaN          NaN\n",
       "3077       CPY015  2025-05-22 08:50:00          NaN          NaN\n",
       "3079       CPY015  2025-05-22 09:10:00          NaN          NaN\n",
       "3081       CPY015  2025-05-22 09:30:00          NaN          NaN\n",
       "3082       CPY015  2025-05-22 09:40:00          NaN          NaN\n",
       "3084       CPY015  2025-05-22 10:00:00          NaN          NaN\n",
       "3085       CPY015  2025-05-22 10:10:00          NaN          NaN\n",
       "3087       CPY015  2025-05-22 10:30:00          NaN          NaN\n",
       "3089       CPY015  2025-05-22 10:50:00          NaN          NaN\n",
       "3092       CPY015  2025-05-22 11:20:00          NaN          NaN\n",
       "3095       CPY015  2025-05-22 11:50:00          NaN          NaN\n",
       "3103       CPY015  2025-05-22 13:10:00          NaN          NaN\n",
       "3104       CPY015  2025-05-22 13:20:00          NaN          NaN\n",
       "3107       CPY015  2025-05-22 13:50:00          NaN          NaN\n",
       "3110       CPY015  2025-05-22 14:20:00          NaN          NaN\n",
       "3113       CPY015  2025-05-22 14:50:00          NaN          NaN\n",
       "3129       CPY015  2025-05-22 17:30:00          NaN          NaN\n",
       "3705       CPY015  2025-05-26 17:30:00          NaN          NaN\n",
       "3792       CPY015  2025-05-27 08:00:00          NaN          NaN\n",
       "3958       CPY015  2025-05-28 11:40:00          NaN          NaN\n",
       "4095       CPY015  2025-05-29 10:30:00          NaN          NaN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display water_level missing values dataset\n",
    "df[df['water_level'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75b71cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_4164\\1151963136.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_final['water_level'].fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_4164\\1151963136.py:2: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_final['water_level'].fillna(method='ffill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Fill the null value with the ffill\n",
    "df_final['water_level'].fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67b3efc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DETAILED DATA QUALITY REPORT ===\n",
      "\n",
      "Missing values:\n",
      "station_code        0\n",
      "measure_datetime    0\n",
      "water_level         0\n",
      "quality_flag        0\n",
      "source_format       0\n",
      "year                0\n",
      "month               0\n",
      "day                 0\n",
      "hour                0\n",
      "dtype: int64\n",
      "\n",
      "Data distribution by year:\n",
      "year\n",
      "2019    52560\n",
      "2020    52704\n",
      "2021    52560\n",
      "2022    52560\n",
      "2023    52560\n",
      "2024    52608\n",
      "2025    21661\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Data distribution by month:\n",
      "month\n",
      "1     31238\n",
      "2     28500\n",
      "3     31234\n",
      "4     30232\n",
      "5     31209\n",
      "6     25920\n",
      "7     26771\n",
      "8     26766\n",
      "9     25904\n",
      "10    26765\n",
      "11    25903\n",
      "12    26771\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Water level statistics:\n",
      "count    337213.000000\n",
      "mean          0.390197\n",
      "std           0.706950\n",
      "min         -26.390000\n",
      "25%          -0.090000\n",
      "50%           0.510000\n",
      "75%           0.900000\n",
      "max          11.540000\n",
      "Name: water_level, dtype: float64\n",
      "\n",
      "Time interval analysis:\n",
      "Most common intervals:\n",
      "measure_datetime\n",
      "0 days 00:10:00    337040\n",
      "0 days 00:20:00       165\n",
      "0 days 00:30:00         7\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Data completeness by year:\n",
      "2019: 52,560 records\n",
      "2020: 52,704 records\n",
      "2021: 52,560 records\n",
      "2022: 52,560 records\n",
      "2023: 52,560 records\n",
      "2024: 52,608 records\n",
      "2025: 21,661 records\n",
      "\n",
      "=== SUMMARY STATISTICS ===\n",
      "Total records: 337,213\n",
      "Date range: 2019-01-01 00:00:00 to 2025-05-31 23:50:00\n",
      "Average water level: 0.39 meters\n",
      "Water level std dev: 0.71 meters\n",
      "Data spans 2342 days\n",
      "\n",
      "=== CLEANED DATA IS READY FOR ANALYSIS ===\n",
      "Use 'df_final' variable for further analysis\n",
      "Cleaned file saved as: 'master_CPY015_cleaned.csv'\n"
     ]
    }
   ],
   "source": [
    "# Data quality assessment and basic analysis\n",
    "\n",
    "print(\"=== DETAILED DATA QUALITY REPORT ===\")\n",
    "\n",
    "# Check for missing values\n",
    "print(f\"\\nMissing values:\")\n",
    "print(df_final.isnull().sum())\n",
    "\n",
    "# Check data distribution by year and month\n",
    "print(f\"\\nData distribution by year:\")\n",
    "year_counts = df_final['year'].value_counts().sort_index()\n",
    "print(year_counts)\n",
    "\n",
    "print(f\"\\nData distribution by month:\")\n",
    "month_counts = df_final['month'].value_counts().sort_index()\n",
    "print(month_counts)\n",
    "\n",
    "# Check for outliers in water level\n",
    "print(f\"\\nWater level statistics:\")\n",
    "print(df_final['water_level'].describe())\n",
    "\n",
    "# Check time frequency (should be mostly 10-minute intervals)\n",
    "df_final_sorted = df_final.sort_values('measure_datetime')\n",
    "time_diffs = df_final_sorted['measure_datetime'].diff()\n",
    "print(f\"\\nTime interval analysis:\")\n",
    "print(f\"Most common intervals:\")\n",
    "print(time_diffs.value_counts().head())\n",
    "\n",
    "# Check for data gaps\n",
    "print(f\"\\nData completeness by year:\")\n",
    "for year in sorted(df_final['year'].unique()):\n",
    "    year_data = df_final[df_final['year'] == year]\n",
    "    print(f\"{year}: {len(year_data):,} records\")\n",
    "    \n",
    "# Basic statistics\n",
    "print(f\"\\n=== SUMMARY STATISTICS ===\")\n",
    "print(f\"Total records: {len(df_final):,}\")\n",
    "print(f\"Date range: {df_final['measure_datetime'].min()} to {df_final['measure_datetime'].max()}\")\n",
    "print(f\"Average water level: {df_final['water_level'].mean():.2f} meters\")\n",
    "print(f\"Water level std dev: {df_final['water_level'].std():.2f} meters\")\n",
    "print(f\"Data spans {(df_final['measure_datetime'].max() - df_final['measure_datetime'].min()).days} days\")\n",
    "\n",
    "print(f\"\\n=== CLEANED DATA IS READY FOR ANALYSIS ===\")\n",
    "print(f\"Use 'df_final' variable for further analysis\")\n",
    "print(f\"Cleaned file saved as: 'master_CPY015_cleaned.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9aafa093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_code</th>\n",
       "      <th>measure_datetime</th>\n",
       "      <th>water_level</th>\n",
       "      <th>quality_flag</th>\n",
       "      <th>source_format</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CPY015</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>0.59</td>\n",
       "      <td>old_format</td>\n",
       "      <td>old</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CPY015</td>\n",
       "      <td>2019-01-01 00:10:00</td>\n",
       "      <td>0.59</td>\n",
       "      <td>old_format</td>\n",
       "      <td>old</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CPY015</td>\n",
       "      <td>2019-01-01 00:20:00</td>\n",
       "      <td>0.61</td>\n",
       "      <td>old_format</td>\n",
       "      <td>old</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CPY015</td>\n",
       "      <td>2019-01-01 00:30:00</td>\n",
       "      <td>0.63</td>\n",
       "      <td>old_format</td>\n",
       "      <td>old</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CPY015</td>\n",
       "      <td>2019-01-01 00:40:00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>old_format</td>\n",
       "      <td>old</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  station_code    measure_datetime  water_level quality_flag source_format  \\\n",
       "0       CPY015 2019-01-01 00:00:00         0.59   old_format           old   \n",
       "1       CPY015 2019-01-01 00:10:00         0.59   old_format           old   \n",
       "2       CPY015 2019-01-01 00:20:00         0.61   old_format           old   \n",
       "3       CPY015 2019-01-01 00:30:00         0.63   old_format           old   \n",
       "4       CPY015 2019-01-01 00:40:00         0.65   old_format           old   \n",
       "\n",
       "   year  month  day  hour  \n",
       "0  2019      1    1     0  \n",
       "1  2019      1    1     0  \n",
       "2  2019      1    1     0  \n",
       "3  2019      1    1     0  \n",
       "4  2019      1    1     0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa68a646",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_final.copy()\n",
    "# Remove station_code column if exists\n",
    "if 'station_code' in df.columns:\n",
    "    df = df.drop(columns=['station_code'])\n",
    "\n",
    "# Change index to measure_datetime\n",
    "if not np.issubdtype(df['measure_datetime'].dtype, np.datetime64):\n",
    "    df['measure_datetime'] = pd.to_datetime(df['measure_datetime'], errors='coerce')\n",
    "df = df.set_index('measure_datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82083b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>water_level</th>\n",
       "      <th>quality_flag</th>\n",
       "      <th>source_format</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>measure_datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:00:00</th>\n",
       "      <td>0.59</td>\n",
       "      <td>old_format</td>\n",
       "      <td>old</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:10:00</th>\n",
       "      <td>0.59</td>\n",
       "      <td>old_format</td>\n",
       "      <td>old</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:20:00</th>\n",
       "      <td>0.61</td>\n",
       "      <td>old_format</td>\n",
       "      <td>old</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:30:00</th>\n",
       "      <td>0.63</td>\n",
       "      <td>old_format</td>\n",
       "      <td>old</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:40:00</th>\n",
       "      <td>0.65</td>\n",
       "      <td>old_format</td>\n",
       "      <td>old</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     water_level quality_flag source_format  year  month  day  \\\n",
       "measure_datetime                                                                \n",
       "2019-01-01 00:00:00         0.59   old_format           old  2019      1    1   \n",
       "2019-01-01 00:10:00         0.59   old_format           old  2019      1    1   \n",
       "2019-01-01 00:20:00         0.61   old_format           old  2019      1    1   \n",
       "2019-01-01 00:30:00         0.63   old_format           old  2019      1    1   \n",
       "2019-01-01 00:40:00         0.65   old_format           old  2019      1    1   \n",
       "\n",
       "                     hour  \n",
       "measure_datetime           \n",
       "2019-01-01 00:00:00     0  \n",
       "2019-01-01 00:10:00     0  \n",
       "2019-01-01 00:20:00     0  \n",
       "2019-01-01 00:30:00     0  \n",
       "2019-01-01 00:40:00     0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67bcd900",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_water = df['water_level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33a7b2cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "measure_datetime\n",
       "2019-01-01 00:00:00    0.59\n",
       "2019-01-01 00:10:00    0.59\n",
       "2019-01-01 00:20:00    0.61\n",
       "2019-01-01 00:30:00    0.63\n",
       "2019-01-01 00:40:00    0.65\n",
       "Name: water_level, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_water.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5d008b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Water level series saved to 'water_level_series.csv'\n"
     ]
    }
   ],
   "source": [
    "# Save water level series to CSV\n",
    "df_water.to_csv('water_level_series.csv', header=['water_level'], index_label='measure_datetime')\n",
    "print(\"Water level series saved to 'water_level_series.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e82a11d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_4164\\1265272697.py:2: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df_hourly = df_water.resample('H').mean()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "measure_datetime\n",
       "2019-01-01 00:00:00    0.621667\n",
       "2019-01-01 01:00:00    0.723333\n",
       "2019-01-01 02:00:00    0.713333\n",
       "2019-01-01 03:00:00    0.695000\n",
       "2019-01-01 04:00:00    0.633333\n",
       "Freq: h, Name: water_level, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample to hourly frequency (mean)\n",
    "df_hourly = df_water.resample('H').mean()\n",
    "df_hourly.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cedb0b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request data from open-meteo.com API for weather data\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "# Define API Endpoint for Past Temperature (URL)\n",
    "url_1 = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "\n",
    "# Define query parameters\n",
    "params_1 = {\n",
    "    \"latitude\": 13.700287,\n",
    "    \"longitude\": 100.492805,\n",
    "    \"hourly\": [\"temperature_2m\", \"rain\", \"showers\", \"cloud_cover\", \"relative_humidity_2m\", \"dew_point_2m\", \"precipitation\", \"weather_code\", \"pressure_msl\", \"surface_pressure\", \"wind_speed_10m\", \"wind_direction_10m\", \"wind_gusts_10m\", \"et0_fao_evapotranspiration\"],\n",
    "    \"start_date\": \"2019-01-01\",\n",
    "    \"end_date\": \"2025-05-31\",\n",
    "    \"timezone\": \"Asia/Bangkok\"\n",
    "}\n",
    "\n",
    "# Make the GET request and assign the response to \"r_1\"\n",
    "r_1 = requests.get(url_1, params=params_1, timeout=15) \n",
    "r_1.raise_for_status()\n",
    "js_1 = r_1.json() # transform to JSON response\n",
    "\n",
    "# Make it dataframe\n",
    "df_weather = pd.DataFrame(js_1['hourly'])\n",
    "df_weather['time'] = pd.to_datetime(df_weather['time'])\n",
    "df_weather = df_weather.set_index('time')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e392303c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature_2m</th>\n",
       "      <th>rain</th>\n",
       "      <th>showers</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>relative_humidity_2m</th>\n",
       "      <th>dew_point_2m</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>weather_code</th>\n",
       "      <th>pressure_msl</th>\n",
       "      <th>surface_pressure</th>\n",
       "      <th>wind_speed_10m</th>\n",
       "      <th>wind_direction_10m</th>\n",
       "      <th>wind_gusts_10m</th>\n",
       "      <th>et0_fao_evapotranspiration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:00:00</th>\n",
       "      <td>23.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>16.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1017.1</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>43</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 01:00:00</th>\n",
       "      <td>22.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>16.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1016.7</td>\n",
       "      <td>1016.6</td>\n",
       "      <td>6.6</td>\n",
       "      <td>22</td>\n",
       "      <td>10.8</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 02:00:00</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>17.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1016.5</td>\n",
       "      <td>1016.4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25</td>\n",
       "      <td>10.4</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 03:00:00</th>\n",
       "      <td>21.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>17.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1016.1</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>28</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 04:00:00</th>\n",
       "      <td>20.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>18.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1015.8</td>\n",
       "      <td>1015.7</td>\n",
       "      <td>7.2</td>\n",
       "      <td>18</td>\n",
       "      <td>8.6</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     temperature_2m  rain  showers  cloud_cover  \\\n",
       "time                                                              \n",
       "2019-01-01 00:00:00            23.5   0.0      0.0            2   \n",
       "2019-01-01 01:00:00            22.7   0.0      0.0            1   \n",
       "2019-01-01 02:00:00            22.0   0.0      0.0            2   \n",
       "2019-01-01 03:00:00            21.4   0.0      0.0            2   \n",
       "2019-01-01 04:00:00            20.7   0.0      0.0            1   \n",
       "\n",
       "                     relative_humidity_2m  dew_point_2m  precipitation  \\\n",
       "time                                                                     \n",
       "2019-01-01 00:00:00                    65          16.6            0.0   \n",
       "2019-01-01 01:00:00                    68          16.4            0.0   \n",
       "2019-01-01 02:00:00                    75          17.3            0.0   \n",
       "2019-01-01 03:00:00                    80          17.8            0.0   \n",
       "2019-01-01 04:00:00                    86          18.3            0.0   \n",
       "\n",
       "                     weather_code  pressure_msl  surface_pressure  \\\n",
       "time                                                                \n",
       "2019-01-01 00:00:00             0        1017.1            1017.0   \n",
       "2019-01-01 01:00:00             0        1016.7            1016.6   \n",
       "2019-01-01 02:00:00             0        1016.5            1016.4   \n",
       "2019-01-01 03:00:00             0        1016.1            1016.0   \n",
       "2019-01-01 04:00:00             0        1015.8            1015.7   \n",
       "\n",
       "                     wind_speed_10m  wind_direction_10m  wind_gusts_10m  \\\n",
       "time                                                                      \n",
       "2019-01-01 00:00:00             6.9                  43            11.2   \n",
       "2019-01-01 01:00:00             6.6                  22            10.8   \n",
       "2019-01-01 02:00:00             6.0                  25            10.4   \n",
       "2019-01-01 03:00:00             5.3                  28             9.4   \n",
       "2019-01-01 04:00:00             7.2                  18             8.6   \n",
       "\n",
       "                     et0_fao_evapotranspiration  \n",
       "time                                             \n",
       "2019-01-01 00:00:00                        0.03  \n",
       "2019-01-01 01:00:00                        0.02  \n",
       "2019-01-01 02:00:00                        0.01  \n",
       "2019-01-01 03:00:00                        0.00  \n",
       "2019-01-01 04:00:00                        0.00  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c0f5cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "temperature_2m                0\n",
       "rain                          0\n",
       "showers                       0\n",
       "cloud_cover                   0\n",
       "relative_humidity_2m          0\n",
       "dew_point_2m                  0\n",
       "precipitation                 0\n",
       "weather_code                  0\n",
       "pressure_msl                  0\n",
       "surface_pressure              0\n",
       "wind_speed_10m                0\n",
       "wind_direction_10m            0\n",
       "wind_gusts_10m                0\n",
       "et0_fao_evapotranspiration    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d105f4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Water level series shape: (56232,)\n",
      "Weather data shape: (56232, 14)\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of both datasets\n",
    "print(f\"Water level series shape: {df_hourly.shape}\")\n",
    "print(f\"Weather data shape: {df_weather.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1da87c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>water_level</th>\n",
       "      <th>temperature_2m</th>\n",
       "      <th>rain</th>\n",
       "      <th>showers</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>relative_humidity_2m</th>\n",
       "      <th>dew_point_2m</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>weather_code</th>\n",
       "      <th>pressure_msl</th>\n",
       "      <th>surface_pressure</th>\n",
       "      <th>wind_speed_10m</th>\n",
       "      <th>wind_direction_10m</th>\n",
       "      <th>wind_gusts_10m</th>\n",
       "      <th>et0_fao_evapotranspiration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>measure_datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:00:00</th>\n",
       "      <td>0.621667</td>\n",
       "      <td>23.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>16.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1017.1</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>43</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 01:00:00</th>\n",
       "      <td>0.723333</td>\n",
       "      <td>22.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>16.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1016.7</td>\n",
       "      <td>1016.6</td>\n",
       "      <td>6.6</td>\n",
       "      <td>22</td>\n",
       "      <td>10.8</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 02:00:00</th>\n",
       "      <td>0.713333</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>17.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1016.5</td>\n",
       "      <td>1016.4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25</td>\n",
       "      <td>10.4</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 03:00:00</th>\n",
       "      <td>0.695000</td>\n",
       "      <td>21.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>17.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1016.1</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>28</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 04:00:00</th>\n",
       "      <td>0.633333</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>18.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1015.8</td>\n",
       "      <td>1015.7</td>\n",
       "      <td>7.2</td>\n",
       "      <td>18</td>\n",
       "      <td>8.6</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     water_level  temperature_2m  rain  showers  cloud_cover  \\\n",
       "measure_datetime                                                               \n",
       "2019-01-01 00:00:00     0.621667            23.5   0.0      0.0            2   \n",
       "2019-01-01 01:00:00     0.723333            22.7   0.0      0.0            1   \n",
       "2019-01-01 02:00:00     0.713333            22.0   0.0      0.0            2   \n",
       "2019-01-01 03:00:00     0.695000            21.4   0.0      0.0            2   \n",
       "2019-01-01 04:00:00     0.633333            20.7   0.0      0.0            1   \n",
       "\n",
       "                     relative_humidity_2m  dew_point_2m  precipitation  \\\n",
       "measure_datetime                                                         \n",
       "2019-01-01 00:00:00                    65          16.6            0.0   \n",
       "2019-01-01 01:00:00                    68          16.4            0.0   \n",
       "2019-01-01 02:00:00                    75          17.3            0.0   \n",
       "2019-01-01 03:00:00                    80          17.8            0.0   \n",
       "2019-01-01 04:00:00                    86          18.3            0.0   \n",
       "\n",
       "                     weather_code  pressure_msl  surface_pressure  \\\n",
       "measure_datetime                                                    \n",
       "2019-01-01 00:00:00             0        1017.1            1017.0   \n",
       "2019-01-01 01:00:00             0        1016.7            1016.6   \n",
       "2019-01-01 02:00:00             0        1016.5            1016.4   \n",
       "2019-01-01 03:00:00             0        1016.1            1016.0   \n",
       "2019-01-01 04:00:00             0        1015.8            1015.7   \n",
       "\n",
       "                     wind_speed_10m  wind_direction_10m  wind_gusts_10m  \\\n",
       "measure_datetime                                                          \n",
       "2019-01-01 00:00:00             6.9                  43            11.2   \n",
       "2019-01-01 01:00:00             6.6                  22            10.8   \n",
       "2019-01-01 02:00:00             6.0                  25            10.4   \n",
       "2019-01-01 03:00:00             5.3                  28             9.4   \n",
       "2019-01-01 04:00:00             7.2                  18             8.6   \n",
       "\n",
       "                     et0_fao_evapotranspiration  \n",
       "measure_datetime                                 \n",
       "2019-01-01 00:00:00                        0.03  \n",
       "2019-01-01 01:00:00                        0.02  \n",
       "2019-01-01 02:00:00                        0.01  \n",
       "2019-01-01 03:00:00                        0.00  \n",
       "2019-01-01 04:00:00                        0.00  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge water level and weather data on datetime index\n",
    "df_merged = pd.merge(df_hourly, df_weather, left_index=True, right_index=True, how='inner')\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cca73899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>river_discharge</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>1131.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02</th>\n",
       "      <td>1139.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-03</th>\n",
       "      <td>1144.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-04</th>\n",
       "      <td>1139.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-05</th>\n",
       "      <td>953.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            river_discharge\n",
       "time                       \n",
       "2019-01-01          1131.40\n",
       "2019-01-02          1139.25\n",
       "2019-01-03          1144.51\n",
       "2019-01-04          1139.25\n",
       "2019-01-05           953.99"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Request data from open-meteo.com API for flood data\n",
    "# Define API Endpoint for Past Temperature (URL)\n",
    "url_2 = \"https://flood-api.open-meteo.com/v1/flood\"\n",
    "\n",
    "# Define query parameters\n",
    "params_2 = {\n",
    "\t\"latitude\": 13.700287,\n",
    "\t\"longitude\": 100.492805,\n",
    "\t\"daily\": \"river_discharge\",\n",
    "    \"start_date\": \"2019-01-01\",\n",
    "    \"end_date\": \"2025-05-31\",\n",
    "    \"timezone\": \"Asia/Bangkok\"\n",
    "}\n",
    "\n",
    "# Make the GET request and assign the response to \"r_1\"\n",
    "r_2 = requests.get(url_2, params=params_2, timeout=15) \n",
    "r_2.raise_for_status()\n",
    "js_2 = r_2.json() # transform to JSON response\n",
    "\n",
    "# Make it dataframe\n",
    "df_flood = pd.DataFrame(js_2['daily'])\n",
    "df_flood['time'] = pd.to_datetime(df_flood['time'])\n",
    "df_flood = df_flood.set_index('time')\n",
    "\n",
    "# Display flood data\n",
    "df_flood.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1c3ae90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of flood data after resampling to hourly: (56232, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_4164\\1819921379.py:6: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  hidx = pd.date_range(s.index.min(),\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>river_discharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:00:00</th>\n",
       "      <td>1131.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 01:00:00</th>\n",
       "      <td>1131.727083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 02:00:00</th>\n",
       "      <td>1132.054167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 03:00:00</th>\n",
       "      <td>1132.381250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 04:00:00</th>\n",
       "      <td>1132.708333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     river_discharge\n",
       "2019-01-01 00:00:00      1131.400000\n",
       "2019-01-01 01:00:00      1131.727083\n",
       "2019-01-01 02:00:00      1132.054167\n",
       "2019-01-01 03:00:00      1132.381250\n",
       "2019-01-01 04:00:00      1132.708333"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample to hourly frequency for flood data\n",
    "# Ensure daily DateTimeIndex and sort\n",
    "s = df_flood[\"river_discharge\"].sort_index().asfreq(\"D\")\n",
    "\n",
    "# Build an hourly index that reaches the last day's 23:00\n",
    "hidx = pd.date_range(s.index.min(),\n",
    "                     s.index.max() + pd.Timedelta(hours=23),\n",
    "                     freq=\"H\")\n",
    "\n",
    "# Interpolate only inside the known span; then carry the last day's value across its remaining hours\n",
    "df_flood_hourly = (\n",
    "    s.reindex(hidx)\n",
    "     .interpolate(method=\"time\", limit_area=\"inside\")\n",
    "     .ffill(limit=23)                                  # fills 01:0023:00 of the last day only\n",
    "     .to_frame(name=\"river_discharge\")\n",
    ")\n",
    "print(f\"Shape of flood data after resampling to hourly: {df_flood_hourly.shape}\")\n",
    "df_flood_hourly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a11cb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the full merge: (56232, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>water_level</th>\n",
       "      <th>temperature_2m</th>\n",
       "      <th>rain</th>\n",
       "      <th>showers</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>relative_humidity_2m</th>\n",
       "      <th>dew_point_2m</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>weather_code</th>\n",
       "      <th>pressure_msl</th>\n",
       "      <th>surface_pressure</th>\n",
       "      <th>wind_speed_10m</th>\n",
       "      <th>wind_direction_10m</th>\n",
       "      <th>wind_gusts_10m</th>\n",
       "      <th>et0_fao_evapotranspiration</th>\n",
       "      <th>river_discharge</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>measure_datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:00:00</th>\n",
       "      <td>0.621667</td>\n",
       "      <td>23.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>16.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1017.1</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>43</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1131.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 01:00:00</th>\n",
       "      <td>0.723333</td>\n",
       "      <td>22.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>16.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1016.7</td>\n",
       "      <td>1016.6</td>\n",
       "      <td>6.6</td>\n",
       "      <td>22</td>\n",
       "      <td>10.8</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1131.727083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 02:00:00</th>\n",
       "      <td>0.713333</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>17.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1016.5</td>\n",
       "      <td>1016.4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25</td>\n",
       "      <td>10.4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1132.054167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 03:00:00</th>\n",
       "      <td>0.695000</td>\n",
       "      <td>21.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>17.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1016.1</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>28</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1132.381250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 04:00:00</th>\n",
       "      <td>0.633333</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>18.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1015.8</td>\n",
       "      <td>1015.7</td>\n",
       "      <td>7.2</td>\n",
       "      <td>18</td>\n",
       "      <td>8.6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1132.708333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     water_level  temperature_2m  rain  showers  cloud_cover  \\\n",
       "measure_datetime                                                               \n",
       "2019-01-01 00:00:00     0.621667            23.5   0.0      0.0            2   \n",
       "2019-01-01 01:00:00     0.723333            22.7   0.0      0.0            1   \n",
       "2019-01-01 02:00:00     0.713333            22.0   0.0      0.0            2   \n",
       "2019-01-01 03:00:00     0.695000            21.4   0.0      0.0            2   \n",
       "2019-01-01 04:00:00     0.633333            20.7   0.0      0.0            1   \n",
       "\n",
       "                     relative_humidity_2m  dew_point_2m  precipitation  \\\n",
       "measure_datetime                                                         \n",
       "2019-01-01 00:00:00                    65          16.6            0.0   \n",
       "2019-01-01 01:00:00                    68          16.4            0.0   \n",
       "2019-01-01 02:00:00                    75          17.3            0.0   \n",
       "2019-01-01 03:00:00                    80          17.8            0.0   \n",
       "2019-01-01 04:00:00                    86          18.3            0.0   \n",
       "\n",
       "                     weather_code  pressure_msl  surface_pressure  \\\n",
       "measure_datetime                                                    \n",
       "2019-01-01 00:00:00             0        1017.1            1017.0   \n",
       "2019-01-01 01:00:00             0        1016.7            1016.6   \n",
       "2019-01-01 02:00:00             0        1016.5            1016.4   \n",
       "2019-01-01 03:00:00             0        1016.1            1016.0   \n",
       "2019-01-01 04:00:00             0        1015.8            1015.7   \n",
       "\n",
       "                     wind_speed_10m  wind_direction_10m  wind_gusts_10m  \\\n",
       "measure_datetime                                                          \n",
       "2019-01-01 00:00:00             6.9                  43            11.2   \n",
       "2019-01-01 01:00:00             6.6                  22            10.8   \n",
       "2019-01-01 02:00:00             6.0                  25            10.4   \n",
       "2019-01-01 03:00:00             5.3                  28             9.4   \n",
       "2019-01-01 04:00:00             7.2                  18             8.6   \n",
       "\n",
       "                     et0_fao_evapotranspiration  river_discharge  \n",
       "measure_datetime                                                  \n",
       "2019-01-01 00:00:00                        0.03      1131.400000  \n",
       "2019-01-01 01:00:00                        0.02      1131.727083  \n",
       "2019-01-01 02:00:00                        0.01      1132.054167  \n",
       "2019-01-01 03:00:00                        0.00      1132.381250  \n",
       "2019-01-01 04:00:00                        0.00      1132.708333  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge water level, weather, flood data on datetime index\n",
    "df_full_merged = df_merged.merge(df_flood_hourly, left_index=True, right_index=True, how=\"outer\", suffixes=(\"_weather\", \"_flood\"))\n",
    "print(f\"Shape of the full merge: {df_full_merged.shape}\")\n",
    "df_full_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "934f457b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "water_level                   0\n",
       "temperature_2m                0\n",
       "rain                          0\n",
       "showers                       0\n",
       "cloud_cover                   0\n",
       "relative_humidity_2m          0\n",
       "dew_point_2m                  0\n",
       "precipitation                 0\n",
       "weather_code                  0\n",
       "pressure_msl                  0\n",
       "surface_pressure              0\n",
       "wind_speed_10m                0\n",
       "wind_direction_10m            0\n",
       "wind_gusts_10m                0\n",
       "et0_fao_evapotranspiration    0\n",
       "river_discharge               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full_merged.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3552e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export full merged dataset to .csv\n",
    "df_full_merged.to_csv('full_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b730b55f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>water_level</th>\n",
       "      <th>temperature_2m</th>\n",
       "      <th>rain</th>\n",
       "      <th>showers</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>relative_humidity_2m</th>\n",
       "      <th>dew_point_2m</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>weather_code</th>\n",
       "      <th>pressure_msl</th>\n",
       "      <th>surface_pressure</th>\n",
       "      <th>wind_speed_10m</th>\n",
       "      <th>wind_direction_10m</th>\n",
       "      <th>wind_gusts_10m</th>\n",
       "      <th>et0_fao_evapotranspiration</th>\n",
       "      <th>river_discharge</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>measure_datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [water_level, temperature_2m, rain, showers, cloud_cover, relative_humidity_2m, dew_point_2m, precipitation, weather_code, pressure_msl, surface_pressure, wind_speed_10m, wind_direction_10m, wind_gusts_10m, et0_fao_evapotranspiration, river_discharge]\n",
       "Index: []"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display dataset that contain missing values\n",
    "df_full_merged[df_full_merged.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb85350f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "measure_datetime\n",
       "2019-01-01 00:00:00    0.621667\n",
       "2019-01-01 01:00:00    0.723333\n",
       "2019-01-01 02:00:00    0.713333\n",
       "2019-01-01 03:00:00    0.695000\n",
       "2019-01-01 04:00:00    0.633333\n",
       "Freq: h, Name: water_level, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_hourly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "acf75b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>water_level</th>\n",
       "      <th>temperature_2m</th>\n",
       "      <th>rain</th>\n",
       "      <th>showers</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>relative_humidity_2m</th>\n",
       "      <th>dew_point_2m</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>weather_code</th>\n",
       "      <th>pressure_msl</th>\n",
       "      <th>surface_pressure</th>\n",
       "      <th>wind_speed_10m</th>\n",
       "      <th>wind_direction_10m</th>\n",
       "      <th>wind_gusts_10m</th>\n",
       "      <th>et0_fao_evapotranspiration</th>\n",
       "      <th>river_discharge</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>measure_datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>0.647222</td>\n",
       "      <td>24.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.875000</td>\n",
       "      <td>65.875000</td>\n",
       "      <td>17.191667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1016.187500</td>\n",
       "      <td>1016.087500</td>\n",
       "      <td>6.916667</td>\n",
       "      <td>70.333333</td>\n",
       "      <td>14.545833</td>\n",
       "      <td>0.169583</td>\n",
       "      <td>1135.161458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02</th>\n",
       "      <td>0.692986</td>\n",
       "      <td>24.195833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.708333</td>\n",
       "      <td>63.041667</td>\n",
       "      <td>16.504167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.625000</td>\n",
       "      <td>1015.558333</td>\n",
       "      <td>1015.458333</td>\n",
       "      <td>7.358333</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>15.433333</td>\n",
       "      <td>0.172917</td>\n",
       "      <td>1141.770417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-03</th>\n",
       "      <td>0.515486</td>\n",
       "      <td>25.362500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.416667</td>\n",
       "      <td>56.916667</td>\n",
       "      <td>16.162500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.583333</td>\n",
       "      <td>1015.370833</td>\n",
       "      <td>1015.270833</td>\n",
       "      <td>12.512500</td>\n",
       "      <td>183.375000</td>\n",
       "      <td>23.650000</td>\n",
       "      <td>0.189167</td>\n",
       "      <td>1141.989583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-04</th>\n",
       "      <td>0.797917</td>\n",
       "      <td>24.812500</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.958333</td>\n",
       "      <td>70.916667</td>\n",
       "      <td>19.008333</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>11.666667</td>\n",
       "      <td>1014.475000</td>\n",
       "      <td>1014.375000</td>\n",
       "      <td>8.550000</td>\n",
       "      <td>93.333333</td>\n",
       "      <td>16.150000</td>\n",
       "      <td>0.099583</td>\n",
       "      <td>1050.479583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-05</th>\n",
       "      <td>1.155833</td>\n",
       "      <td>24.516667</td>\n",
       "      <td>0.179167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>75.375000</td>\n",
       "      <td>19.812500</td>\n",
       "      <td>0.179167</td>\n",
       "      <td>15.666667</td>\n",
       "      <td>1013.595833</td>\n",
       "      <td>1013.495833</td>\n",
       "      <td>11.662500</td>\n",
       "      <td>211.250000</td>\n",
       "      <td>22.833333</td>\n",
       "      <td>0.085833</td>\n",
       "      <td>809.348750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  water_level  temperature_2m      rain  showers  cloud_cover  \\\n",
       "measure_datetime                                                                \n",
       "2019-01-01           0.647222       24.200000  0.000000      0.0    55.875000   \n",
       "2019-01-02           0.692986       24.195833  0.000000      0.0    86.708333   \n",
       "2019-01-03           0.515486       25.362500  0.000000      0.0    83.416667   \n",
       "2019-01-04           0.797917       24.812500  0.125000      0.0    99.958333   \n",
       "2019-01-05           1.155833       24.516667  0.179167      0.0   100.000000   \n",
       "\n",
       "                  relative_humidity_2m  dew_point_2m  precipitation  \\\n",
       "measure_datetime                                                      \n",
       "2019-01-01                   65.875000     17.191667       0.000000   \n",
       "2019-01-02                   63.041667     16.504167       0.000000   \n",
       "2019-01-03                   56.916667     16.162500       0.000000   \n",
       "2019-01-04                   70.916667     19.008333       0.125000   \n",
       "2019-01-05                   75.375000     19.812500       0.179167   \n",
       "\n",
       "                  weather_code  pressure_msl  surface_pressure  \\\n",
       "measure_datetime                                                 \n",
       "2019-01-01            1.666667   1016.187500       1016.087500   \n",
       "2019-01-02            2.625000   1015.558333       1015.458333   \n",
       "2019-01-03            2.583333   1015.370833       1015.270833   \n",
       "2019-01-04           11.666667   1014.475000       1014.375000   \n",
       "2019-01-05           15.666667   1013.595833       1013.495833   \n",
       "\n",
       "                  wind_speed_10m  wind_direction_10m  wind_gusts_10m  \\\n",
       "measure_datetime                                                       \n",
       "2019-01-01              6.916667           70.333333       14.545833   \n",
       "2019-01-02              7.358333          138.000000       15.433333   \n",
       "2019-01-03             12.512500          183.375000       23.650000   \n",
       "2019-01-04              8.550000           93.333333       16.150000   \n",
       "2019-01-05             11.662500          211.250000       22.833333   \n",
       "\n",
       "                  et0_fao_evapotranspiration  river_discharge  \n",
       "measure_datetime                                               \n",
       "2019-01-01                          0.169583      1135.161458  \n",
       "2019-01-02                          0.172917      1141.770417  \n",
       "2019-01-03                          0.189167      1141.989583  \n",
       "2019-01-04                          0.099583      1050.479583  \n",
       "2019-01-05                          0.085833       809.348750  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample to daily frequency for full merge(mean)\n",
    "df_full_merged_daily = df_full_merged.resample('D').mean()\n",
    "df_full_merged_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f328ce40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2343, 16)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full_merged_daily.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eeb4663a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "df_full_merged_daily.to_csv('full_merged_daily.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d6ec7445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of full_merged_daily: (2343, 16)\n",
      "Shape of full_merged: (56232, 16)\n"
     ]
    }
   ],
   "source": [
    "# Remove not related .csv filename\n",
    "os.remove('master_CPY015.csv')\n",
    "os.remove('water_level_series.csv')\n",
    "os.remove('master_CPY015_cleaned.csv')\n",
    "\n",
    "print(\"Shape of full_merged_daily:\", df_full_merged_daily.shape)\n",
    "print(\"Shape of full_merged:\", df_full_merged.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0e6113",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ait",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
